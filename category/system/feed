<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wklken's blog</title><link>http://www.wklken.me/</link><description></description><atom:link href="http://www.wklken.me/category/system/feed" rel="self"></atom:link><lastBuildDate>Tue, 24 May 2016 00:00:00 +0800</lastBuildDate><item><title>Logstash+ElasticSearch处理mysql慢查询日志</title><link>http://www.wklken.me/posts/2016/05/24/elk-mysql-slolog.html</link><description>&lt;p&gt;遇到一个需求, 需要查询某些业务的慢查询日志. 结果DBA平台那边提供的慢查询日志不能解决实际的业务场景(上报的字段补全), 无奈, 自己挽起袖子上&lt;/p&gt;
&lt;p&gt;参考了 &lt;a href="https://www.phase2technology.com/blog/adding-mysql-slow-query-logs-to-logstash/"&gt;这篇文章&lt;/a&gt;, 不过自己根据需求做了较多的变更&lt;/p&gt;
&lt;p&gt;开始吧&lt;/p&gt;
&lt;h2 id="1"&gt;1. 找到日志的位置&lt;/h2&gt;
&lt;p&gt;先确认是否开启了, 然后找到日志文件的位置&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;gt; show variables like '%slow%';
+---------------------+-------------------------------------+
| Variable_name       | Value                               |
+---------------------+-------------------------------------+
| log_slow_queries    | ON                                  |
| slow_launch_time    | 2                                   |
| slow_query_log      | ON                                  |
| slow_query_log_file | /data/mysqllog/20000/slow-query.log |
+---------------------+-------------------------------------+
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="2"&gt;2. 慢查询日志&lt;/h2&gt;
&lt;p&gt;格式基本是如下, 当然, 格式如果有差异, 需要根据具体格式进行小的修改&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# Time: 160524  5:12:29
# User@Host: user_a[xxxx] @  [10.166.140.109]
# Query_time: 1.711086  Lock_time: 0.000040 Rows_sent: 385489  Rows_examined: 385489
use dbname;
SET timestamp=1464037949;
SELECT 1 from dbname;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="3-logstash"&gt;3. 使用 logstash 采集&lt;/h2&gt;
&lt;p&gt;采集, 无非是用&lt;code&gt;multiline&lt;/code&gt;进行多行解析&lt;/p&gt;
&lt;p&gt;但是, 需要处理的&lt;/p&gt;
&lt;p&gt;第一个是, 去除掉没用的信息&lt;/p&gt;
&lt;p&gt;第二个, 慢查询sql, 是会反复出现的, 所以, 执行次数成了一个很重要的指标. 我们要做的, 就是&lt;code&gt;降噪&lt;/code&gt;(将参数去掉, 涉及带引号的内容+数字), 将参数类信息过滤掉, 留下核心的sql, 然后计算出一个hash, 这样就可以在查询, 根据这个字段进行聚合. 这里用到了 &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-add_field"&gt;mutate&lt;/a&gt; 以及 &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-checksum.html"&gt;checksum&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;  # calculate unique hash
  mutate {
    add_field =&amp;gt; {"sql_for_hash" =&amp;gt; "%{sql}"}
  }
  mutate {
    gsub =&amp;gt; [
        "sql_for_hash", "'.+?'", "",
        "sql_for_hash", "-?\d*\.{0,1}\d+", ""
    ]
  }
  checksum {
    algorithm =&amp;gt; "md5"
    keys =&amp;gt; ["sql_for_hash"]
  }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最后算出来的md5, 放入了&lt;code&gt;logstash_checksum&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;完整的logstash配置文件(具体使用可能需要根据自身日志格式做些小调整)
注意, 里面的pattern &lt;code&gt;ALLWORD [\s\S]*&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"/data/mysqllog/20000/slow-query.log"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;sincedb_path&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s2"&gt;"/data/LogNew/logstash/sincedb/mysql.sincedb"&lt;/span&gt;
    &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s2"&gt;"mysql-slow-log"&lt;/span&gt;
    &lt;span class="n"&gt;add_field&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"env"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"PRODUCT"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;codec&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;multiline&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s2"&gt;"^# User@Host:"&lt;/span&gt;
      &lt;span class="n"&gt;negate&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;true&lt;/span&gt;
      &lt;span class="n"&gt;what&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;previous&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="nt"&gt;filter&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;grok&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="n"&gt;Host&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;logstash&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;logstash&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt; &lt;span class="n"&gt;localhost&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;127.0.0.1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="n"&gt;Host&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;logstash&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;logstash&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt; &lt;span class="o"&gt;@&lt;/span&gt;  &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;127.0.0.1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"^# User@Host: %{ALLWORD:user}\[%{ALLWAORD}\] @ %{ALLWORD:dbhost}? \[%{IP:ip}\]"&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;grok&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Query_time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;102&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;413328&lt;/span&gt;  &lt;span class="n"&gt;Lock_time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;000167&lt;/span&gt; &lt;span class="n"&gt;Rows_sent&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="n"&gt;Rows_examined&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1970&lt;/span&gt;
    &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"^# Query_time: %{NUMBER:duration:float}%{SPACE}Lock_time: %{NUMBER:lock_wait:float}%{SPACE}Rows_sent: %{NUMBER:results:int}%{SPACE}Rows_examined:%{SPACE}%{NUMBER:scanned:int}%{ALLWORD:sql}"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="nt"&gt;remove&lt;/span&gt; &lt;span class="nt"&gt;useless&lt;/span&gt; &lt;span class="nt"&gt;data&lt;/span&gt;
  &lt;span class="nt"&gt;mutate&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;gsub&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;SET timestamp=\d+?;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;use [a-zA-Z0-9\-\_]+?;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;# Time: \d+\s+\d+:\d+:\d+"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;/usr/local/mysql/bin/mysqld.+$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Tcp port:.+$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Time .+$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
    &lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;Capture&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;time&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;query&lt;/span&gt; &lt;span class="nt"&gt;happened&lt;/span&gt;
  &lt;span class="nt"&gt;grok&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"^SET timestamp=%{NUMBER:timestamp};"&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;date&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"timestamp"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"UNIX"&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;


  &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;calculate&lt;/span&gt; &lt;span class="nt"&gt;unique&lt;/span&gt; &lt;span class="nt"&gt;hash&lt;/span&gt;
  &lt;span class="nt"&gt;mutate&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;add_field&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s2"&gt;"%{sql}"&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;mutate&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;gsub&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;
        &lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"'.+?'"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"-?\d*\.{0,1}\d+"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
    &lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nt"&gt;checksum&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;algorithm&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s2"&gt;"md5"&lt;/span&gt;
    &lt;span class="n"&gt;keys&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;Drop&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;captured&lt;/span&gt; &lt;span class="nt"&gt;timestamp&lt;/span&gt; &lt;span class="nt"&gt;field&lt;/span&gt; &lt;span class="nt"&gt;since&lt;/span&gt; &lt;span class="nt"&gt;it&lt;/span&gt; &lt;span class="nt"&gt;has&lt;/span&gt; &lt;span class="nt"&gt;been&lt;/span&gt; &lt;span class="nt"&gt;moved&lt;/span&gt; &lt;span class="nt"&gt;to&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;time&lt;/span&gt; &lt;span class="nt"&gt;of&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;event&lt;/span&gt;
  &lt;span class="nt"&gt;mutate&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;TODO&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;remove&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="n"&gt;field&lt;/span&gt;
    &lt;span class="n"&gt;remove_field&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"timestamp"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="nt"&gt;output&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="m"&gt;#stdout&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt;    &lt;span class="n"&gt;codec&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;rubydebug&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="nn"&gt;#if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"_grokparsefailure"&lt;/span&gt; &lt;span class="nt"&gt;not&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tags&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt;    &lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt;        &lt;span class="n"&gt;codec&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;rubydebug&lt;/span&gt;
    &lt;span class="err"&gt;#&lt;/span&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="err"&gt;#}&lt;/span&gt;
    &lt;span class="nt"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"_grokparsefailure"&lt;/span&gt; &lt;span class="nt"&gt;not&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tags&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;elasticsearch&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
          &lt;span class="n"&gt;hosts&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"192.168.1.1:9200"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
          &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s2"&gt;"logstash-slowlog"&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;采集进去的内容&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{
           "@timestamp" =&amp;gt; "2016-05-23T21:12:59.000Z",
             "@version" =&amp;gt; "1",
                 "tags" =&amp;gt; [
        [0] "multiline"
    ],
                 "path" =&amp;gt; "/Users/ken/tx/elk/logstash/data/slow_sql.log",
                 "host" =&amp;gt; "Luna-mac-2.local",
                 "type" =&amp;gt; "mysql-slow",
                  "env" =&amp;gt; "PRODUCT",
                 "user" =&amp;gt; "dba_bak_all_sel",
                   "ip" =&amp;gt; "10.166.140.109",
             "duration" =&amp;gt; 28.812601,
            "lock_wait" =&amp;gt; 0.000132,
              "results" =&amp;gt; 749414,
              "scanned" =&amp;gt; 749414,
                  "sql" =&amp;gt; "SELECT /*!40001 SQL_NO_CACHE */ * FROM `xxxxx`;",
    "logstash_checksum" =&amp;gt; "3e3ccb89ee792de882a57e2bef6c5371"
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="4"&gt;4. 写查询&lt;/h2&gt;
&lt;p&gt;查询, 我们需要按&lt;code&gt;logstash_checksum&lt;/code&gt;进行聚合, 然后按照次数由多到少降序展示, 同时, 每个&lt;code&gt;logstash_checksum&lt;/code&gt;需要有一条具体的sql进行展示&lt;/p&gt;
&lt;p&gt;通过 es 的 &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html"&gt;Top hits Aggregation&lt;/a&gt; 可以完美地解决这个查询需求&lt;/p&gt;
&lt;p&gt;查询的query&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;body = {
    "from": 0,
    "size": 0,
    "query": {
        "filtered": {
            "query": {
                "match": {
                    "user": "test"
                }
            },
            "filter": {
                "range": {
                    "@timestamp": {
                        "gte": "now-1d",
                        "lte": "now"
                    }
                }
            }
        }
    },
    "aggs": {
        "top_errors": {
            "terms": {
                "field": "logstash_checksum",
                "size": 20
            },
            "aggs": {
                "top_error_hits": {
                    "top_hits": {
                        "sort": [
                            {
                                "@timestamp":{
                                    "order": "desc"
                                }
                            }
                        ],
                        "_source": {
                            "include": [
                               "user" , "sql", "logstash_checksum", "@timestamp", "duration", "lock_wait", "results", "scanned"
                            ]
                        },
                        "size" : 1
                    }
                }
            }
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;跟这个写法相关的几个参考链接: &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation"&gt;Terms Aggregation&lt;/a&gt; /  &lt;a href="http://stackoverflow.com/questions/25986538/elasticsearch-filter-document-group-by-field"&gt;Elasticsearch filter document group by field&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="5"&gt;5. 渲染页面&lt;/h2&gt;
&lt;p&gt;python的后台, 使用&lt;code&gt;sqlparse&lt;/code&gt;包, 将sql进行格式化(换行/缩进/大小写), 再往前端传. &lt;a href="https://pypi.python.org/pypi/sqlparse"&gt;sqlparse&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;gt;&amp;gt;&amp;gt; sql = 'select * from foo where id in (select id from bar);'
&amp;gt;&amp;gt;&amp;gt; print sqlparse.format(sql, reindent=True, keyword_case='upper')
SELECT *
FROM foo
WHERE id IN
  (SELECT id
   FROM bar);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后在页面上, 使用js进行语法高亮  &lt;a href="https://github.com/google/code-prettify"&gt;code-prettify&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Tue, 24 May 2016 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2016-05-24:posts/2016/05/24/elk-mysql-slolog.html</guid><category>system</category></item><item><title>ELK维护的一些点(二)</title><link>http://www.wklken.me/posts/2016/05/07/elk-about-2.html</link><description>&lt;p&gt;很杂, 涉及到最近处理的一些点&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="string"&gt;根据string转浮点数的某个字段排序&lt;/h3&gt;
&lt;p&gt;一个字段, &lt;code&gt;resp_time&lt;/code&gt;, mapping中是string, 有需求是, 按照响应时间降序排序, 此时需要构造qsl(在search中使用), 使用该字段转换为浮点数, 降序排列&lt;/p&gt;
&lt;p&gt;第一步, 修改es配置, 增加groovy支持&lt;/p&gt;
&lt;p&gt;elasticsearch.yml中加入&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;script.engine.groovy.inline.search: on
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, 执行 &lt;a href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html#rolling-restart"&gt;rolling restart&lt;/a&gt;, 逐一重启集群每个节点&lt;/p&gt;
&lt;p&gt;第二步, 构造qsl,  &lt;code&gt;sort&lt;/code&gt;中,  增加&lt;code&gt;_script&lt;/code&gt; 使用groovy脚本, 将对应字段从string转成数字, 再进行排序&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;'sort': [{'_script': {'lang': 'groovy',
                       'order': 'desc',
                       'script': 'Float.parseFloat(doc["resp_time"].value)',
                       'type': 'number'}},
          {'@timestamp': 'desc'}
          ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;附 &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html"&gt;scripting文档&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="fielddata-format-disabled"&gt;&lt;code&gt;fielddata-format-disabled&lt;/code&gt;导致的排序失效&lt;/h3&gt;
&lt;p&gt;有个集群, 升级后, 发现&lt;code&gt;resp_time&lt;/code&gt;字段的mapping是&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;"resp_time" : {
"type" : "string",
"norms" : {
    "enabled" : false
},
"fielddata" : {
    "format" : "disabled"
},
"fields" : {
    "raw" : {
    "type" : "string",
    "index" : "not_analyzed",
    "ignore_above" : 256
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意这里的, 是因为升级es 2.0之后, 默认值变更带来的问题&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;"fielddata" : {
  "format" : "disabled"
},
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html"&gt;fielddata文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;此时, 排序的qsl将会报错, 无法按照对应要求排序&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Field data loading is forbidden on resp_time
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;解决方案, 挺简单的, 使用&lt;code&gt;foo.raw&lt;/code&gt;即可&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;'sort': [{'_script': {'lang': 'groovy',
    'order': 'desc',
    'script': 'Float.parseFloat(doc["resp_time.raw"].value)',
    'type': 'number'}},
{'@timestamp': 'desc'}
]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="_1"&gt;使用聚合&lt;/h3&gt;
&lt;p&gt;把string类型的&lt;code&gt;resp_time&lt;/code&gt;放到&lt;code&gt;aggs&lt;/code&gt;中做聚合的时候.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;"aggs": {
     "resp_time_stats": {"stats": {"script": 'Float.parseFloat(doc["resp_time.raw"].value)'}}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 会报错&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{u'error': {u'failed_shards': [{u'index': u'logstash-2016.04.10',
                                u'node': u'AvemqKN-RGKy68zJXUapBg',
                                u'reason': {u'reason': u'scripts of type [inline], operation [aggs] and lang [groovy] are disabled',
                                            u'type': u'script_exception'},
                                u'shard': 0}],
            u'grouped': True,
            u'phase': u'query',
            u'reason': u'all shards failed',
            u'root_cause': [{u'reason': u'scripts of type [inline], operation [aggs] and lang [groovy] are disabled',
                             u'type': u'script_exception'}],
            u'type': u'search_phase_execution_exception'},
 u'status': 500}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理, es加配置, 逐一重启&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;script.engine.groovy.inline.aggs: on
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;相关 &lt;a href="https://discuss.elastic.co/t/scripts-of-type-inline-operation-aggs-and-lang-groovy-are-disabled/2493"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="logstash-grok-default-patterns"&gt;logstash grok default patterns&lt;/h3&gt;
&lt;p&gt;默认的一些pattern, 见 &lt;a href="https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns"&gt;grok-patterns&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;grok检查在线实时编辑, https://grokdebug.herokuapp.com/&lt;/p&gt;
&lt;h3 id="logstash-codec-multiline"&gt;logstash codec multiline 限制行数和日志大小&lt;/h3&gt;
&lt;p&gt;配置, 具体见 &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-codecs-multiline.html"&gt;multiline文档&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;input {
        codec =&amp;gt; multiline {
            patterns_dir =&amp;gt; "./patterns"
            pattern =&amp;gt; ""
            what =&amp;gt; "previous"
            negate  =&amp;gt; true
            max_lines =&amp;gt; 100
            max_bytes =&amp;gt; "50kib"
        }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;单位 &lt;a href="https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html#bytes"&gt;bytes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;实践中, 使用&lt;code&gt;max_bytes&lt;/code&gt;, 当&lt;code&gt;what=previous + negate=true&lt;/code&gt;的情况下, 即不匹配模式的, 归属前一部分, 这种情况下, 性能ok, 反之&lt;code&gt;what=next + negate=true&lt;/code&gt;的情况下, 不匹配成功归属于后半部分, 此时产生的cpu消耗非常之大, 可以将一台机器跑满.&lt;/p&gt;
&lt;p&gt;另外, 假设配置&lt;code&gt;max_bytes=1M&lt;/code&gt;, 此时用户打了50M, 会给这个event打上tag &lt;code&gt;multiline_codec_max_bytes_reache&lt;/code&gt;, 但是, 这50M 最终还是会经logstash灌入到es里面. 即, 超了, 但是并不自动截掉&lt;/p&gt;
&lt;p&gt;这时候, 我们可以, 使用&lt;code&gt;mutate-replace&lt;/code&gt;直接替换掉&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    # if multiline_codec_max_lines_reached
    if ("multiline_codec_max_bytes_reached" in [tags]) {
        mutate {
            replace =&amp;gt; {
                "message" =&amp;gt; "Log System Warnning: multiline_codec_max_lines_reached, Your log has exceeded 50kB(51200 chars), it was blocked by log system. Please check your code to make your log info shorter and useful"
                "msg" =&amp;gt; "Log System Warnning: multiline_codec_max_lines_reached, Your log has exceeded 50kB(51200 chars), it was blocked by log system. Please check your code to make your log info shorter and useful"
            }
        }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="supervisordlogstash"&gt;使用supervisord管理logstash进程&lt;/h3&gt;
&lt;p&gt;之前提到, 升级集群后, 使用supervisord统一管理logstash进程, &lt;a href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html#supervisord"&gt;链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="logstashtop"&gt;查看当前机器logstash进程top&lt;/h3&gt;
&lt;p&gt;有时, 需要上机器看看对应采集端所有logstash进程是否存在问题, 常常用到&lt;code&gt;top&lt;/code&gt;命令, 所以写了个简单的脚本, 配合supervisord的脚本使用&lt;/p&gt;
&lt;p&gt;ltop.sh&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
./logstashd.sh status
top -p &lt;span class="k"&gt;$(&lt;/span&gt;./logstashd.sh status &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;'{print $4}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk -F&lt;span class="s1"&gt;','&lt;/span&gt; &lt;span class="s1"&gt;'{print $1}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; tr &lt;span class="s1"&gt;'\n'&lt;/span&gt; &lt;span class="s1"&gt;','&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;'s/,$//g'&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="cpu"&gt;进程占用cpu检测脚本&lt;/h3&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nv"&gt;BASEDIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;dirname &lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$BA&lt;/span&gt;SEDIR
&lt;span class="nv"&gt;CURRENT_DIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; &amp;gt;&amp;gt; /tmp/log/monitor.log 2&amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;1
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"=============================================="&lt;/span&gt;
date
&lt;span class="k"&gt;function&lt;/span&gt; check&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nv"&gt;PNAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;
    &lt;span class="nv"&gt;PID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;
    &lt;span class="nv"&gt;CPU_USE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;ps -p $PID -o %cpu &lt;span class="p"&gt;|&lt;/span&gt; sed -n &lt;span class="s1"&gt;'2p'&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;INT_CPU_USE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;printf&lt;/span&gt; &lt;span class="s2"&gt;"%.0f\n"&lt;/span&gt; &lt;span class="nv"&gt;$C&lt;/span&gt;PU_USE&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; $PNAME&lt;span class="s2"&gt;" - "&lt;/span&gt;&lt;span class="nv"&gt;$C&lt;/span&gt;PU_USE&lt;span class="s2"&gt;" - "&lt;/span&gt;$INT_CPU_USE

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; $INT_CPU_USE -gt &lt;span class="m"&gt;85&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;then&lt;/span&gt;
       &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;$&lt;span class="s2"&gt;PNAME cpu usage greater than 85%,do restart"&lt;/span&gt;
       ./logstashd.sh restart $PNAME
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; -f check
./logstashd.sh status &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;'{print "-", $1, $4}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk -F&lt;span class="s1"&gt;','&lt;/span&gt; &lt;span class="s1"&gt;'{print $1}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; xargs -n3 bash -c &lt;span class="s1"&gt;'check $@'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="yellow"&gt;数据盘满了导致集群状态yellow&lt;/h3&gt;
&lt;p&gt;机器节点本身有1T 硬盘, 由两块盘组成, 配置es的时候, 数据分别写到了两个盘上, 然后有一天集群状态告警了&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;"status" : "yellow",
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看es的日志&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[2016-03-21 12:43:45,934][INFO ][cluster.routing.allocation.decider] [node_01] low disk watermark [85%] exceeded
on [AvemqKN-RGKy68zJXUapBg][node_01][/data/LogNewData/xxx/nodes/0] free: 75.5gb[14.1%], replicas will not be assigned to this node
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理: 腾磁盘空间出来, es会自动检测恢复&lt;/p&gt;
&lt;p&gt;PS: 磁盘大小要预估好&lt;/p&gt;
&lt;h3 id="redis"&gt;查看redis中队列的堆积&lt;/h3&gt;
&lt;p&gt;历史遗留问题, 有些节点采集发送到redis的key, 在indexer阶段并没有被消费, 导致越堆越多....&lt;/p&gt;
&lt;p&gt;这时候, 可以通过redis查下哪些队列堆积了&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;bin/redis-cli -h 127.0.0.1 -p 6379 -a blueking_log --bigkeys
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;需要redis版本支持&lt;code&gt;bigkeys&lt;/code&gt; =&amp;gt; This is a "new" feature beginning with 2.8&lt;/p&gt;
&lt;h3 id="_2"&gt;解析失败丢弃及黑名单实现&lt;/h3&gt;
&lt;p&gt;grok解析失败, 丢弃&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;if ("_grokparsefailure" in [tags]) {
    drop {}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;有时候, 需要禁止采集某些文件, 但由于&lt;code&gt;file&lt;/code&gt;类型的&lt;code&gt;exclude&lt;/code&gt;只能用文件名, 而没有更强大的规则, 所以只能采集进来再丢弃, 此时, 可以根据路径grok解析出关键字, 然后判断丢弃&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;if ([keyworod] in ["data", "not_exists"])
{
    drop {}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="worker"&gt;启动限制使用的worker数&lt;/h3&gt;
&lt;p&gt;默认情况, 有可能把所有cpu跑满, 这时候, 可以专门加下&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;-w, --pipeline-workers COUNT  Sets the number of pipeline workers to run. (default: 24)

logstash agent -f conf/xxx.conf -w 2
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="_3"&gt;几个简单脚本&lt;/h3&gt;
&lt;p&gt;health.sh&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
curl &lt;span class="s1"&gt;'http://127.0.0.1:9200/_cluster/health?pretty=true'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;indices.sh&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
curl &lt;span class="s1"&gt;'http://127.0.0.1:9200/_cat/indices?v'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort -k 3
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sat, 07 May 2016 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2016-05-07:posts/2016/05/07/elk-about-2.html</guid><category>system</category></item><item><title>ELK 维护的一些点</title><link>http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html</link><description>&lt;p&gt;去年入职新公司之后, 负责维护平台的elk&lt;/p&gt;
&lt;p&gt;这套东西是2013年搭建的, 年久失修, 所以做了个方案, 开始了批量升级&lt;/p&gt;
&lt;p&gt;将logstash从1.3升级到2.1, 将elasticsearch从1.4.1升级到2.0&lt;/p&gt;
&lt;p&gt;期间踩了很多坑, 搞了一个多月, 总算搞完&lt;/p&gt;
&lt;p&gt;从纯手工落后隔三差五有人找查问题的自行车, 改成自动化最新版本新架构运维便捷上了两个月无人反馈的, 额, 小汽车:) - 集成安装包/shell脚本/fabric实现部署/升级/增删/加黑名单等等功能&lt;/p&gt;
&lt;p&gt;每天日志量大概10G上下, 几十个采集端, 两个redis, 两个indexer, 两台es机器扛起&lt;/p&gt;
&lt;p&gt;以下, 不那么严谨地, 记录一些遇到的问题&lt;/p&gt;
&lt;h4 id="1-logstash"&gt;1. logstash升级策略&lt;/h4&gt;
&lt;p&gt;logstash1.3到2.x, 变化点还是很多的&lt;/p&gt;
&lt;p&gt;所以, 首先第一步要去阅读官方文档, 将所有change log过一遍, 对一些关键性的东西进行了解, 比如, 干掉了哪些语法(旧的功能需要如何实现), 哪些语法有变更, 新增了哪些特性等.&lt;/p&gt;
&lt;p&gt;然后, 将线上不同类型agent的配置文件拉下来, 先, 归类, 然后, 开始改-测-改-测-直到测试通过&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;bin/logstash agent -t -f test.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;直到, 语法验证通过&lt;/p&gt;
&lt;p&gt;现在要做的是, 验证数据正确性&lt;/p&gt;
&lt;p&gt;从线上拉取对应日志, 启动, 查看输出&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;output {
    stdout{
        debug =&amp;gt; true
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里需要验证的是, 1. 过滤, 该过滤的过滤了 2. 转换, 该转换的转换了 3.新增, 新增字段&lt;/p&gt;
&lt;p&gt;注意, 测试时, 使用逻辑分支覆盖到所有配置文件中的分支即可.&lt;/p&gt;
&lt;p&gt;然后, 可以挑一台机器, 停老的服务, 部署新的服务进行测试&lt;/p&gt;
&lt;p&gt;建议, 部署agent的时候, 如果读的是文件, 建议配置&lt;code&gt;sincedb_path&lt;/code&gt; 这样假设下次升级, 就可以从老的服务最后读取的位置开始了&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;input {
    file {
        path =&amp;gt; ["/data/logs/*.log"]
        sincedb_path =&amp;gt; "/data/LogNew/logstash/sincedb/celery.sincedb"
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="2-elasticsearch"&gt;2. elasticsearch升级的策略&lt;/h4&gt;
&lt;p&gt;elasticsearch从1.4到2.0, 部署上变化不大, 变化最大的是存储doc的schema变了......&lt;/p&gt;
&lt;p&gt;使用原来的语法查询, 发现查不到, 因为字段名以及嵌套层级完全不一样了, 这里, 要修改查询端, 兼容新老版本的格式&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{'from': 0,
 'query': {'filtered': {'filter': {'bool': {'must': [{'bool': {'should': [{'term': {'type': 'app'}},
                                                                          {'term': {'@type': 'app'}}]}},
                                                     {'bool': {'should': [{'term': {'log_level': u'error'}},
                                                                          {'term': {'@fields.log_level': u'error'}}]}},
                                                     {'range': {'@timestamp': {'gt': 'now-5h'}}},
                                                     {'bool': {'should': [{'term': {'log_type': u'celery'}},
                                                                          {'term': {'@fields.log_type': u'celery'}}]}}]}}}},
 'size': 100,
 'sort': [{'@timestamp': 'desc'}]}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;另一个是, 取到数据进行解析的时候, 发现解析逻辑跪了, 没办法, 返回的json也完全变了, 这里, 要修改解析逻辑, 兼容新老版本格式&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;for hit in log_hits:
    try:
        source = hit.get('_source')
        if '@fields' in source:
            log = source.get('@fields', {})
        else:
            log = source
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;为了让用户感觉不到集群升级, 首先要做的就是上面两个变更&lt;/p&gt;
&lt;p&gt;然后, 搭建新的集群, 最好找新的机器搭建(我在新的机器搭完才发现妈蛋硬盘才100G, 坑死, 无奈在老集群上搭新的集群, 硬盘1t)&lt;/p&gt;
&lt;p&gt;ready, 所有节点起好维护好, 然后, 改indexer, 将同一份日志灌到两个集群&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;output {
    elasticsearch {
        hosts =&amp;gt; ["10.1.1.1:9100", "10.1.1.2:9100"]
    }
    elasticsearch {
        hosts =&amp;gt; ["10.1.1.1:9110", "10.1.1.2:9110"]
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;简单测试下, 没问题就放着甭管了, 等数据攒齐了....&lt;/p&gt;
&lt;p&gt;数据够了, 就, 停indexer, 停老集群, 停新集群, 改新集群端口, 起来....同时去掉indexer只输出到新的集群, 起来......测试, 切换完毕, 收工吧.&lt;/p&gt;
&lt;h4 id="supervisord"&gt;优化点: 集成安装包和supervisord&lt;/h4&gt;
&lt;p&gt;额, logstash和es, 如果要配置节点, 其实还是挺蛋疼的&lt;/p&gt;
&lt;p&gt;要做的, 就是, logstash+不同类型配置文件+运维脚本, 达成一个包&lt;/p&gt;
&lt;p&gt;然后, 如果要部署一台机器, 扔上去一键执行安装, 测试, 启动即可&lt;/p&gt;
&lt;p&gt;例如, 运维脚本 &lt;code&gt;logstashd.sh&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;BASEDIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;dirname &lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$BA&lt;/span&gt;SEDIR
&lt;span class="nv"&gt;CURRENT_DIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="k"&gt;function&lt;/span&gt; help_msg&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"===================== usage ====================="&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh  - enter command line"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh status - show all configured process"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh start &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - start program"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh stop &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - stop program"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh restart &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - restart program"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh reread &amp;amp;&amp;amp; ./logstashd.sh update - update config and just update the modified programs"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh reload - reload config files and restart all programs(stopeed not included)"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"================================================="&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"-h"&lt;/span&gt; -o &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"--help"&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    help_msg
    &lt;span class="nb"&gt;exit&lt;/span&gt; 0
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;SUPERVISORCTL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'/data/LogNew/python27/bin/supervisorctl'&lt;/span&gt;

&lt;span class="nv"&gt;CONFIG_FILE_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CURRENT_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/conf/supervisord.conf"&lt;/span&gt;

$SUPERVISORCTL -c &lt;span class="nv"&gt;$C&lt;/span&gt;ONFIG_FILE_PATH &lt;span class="nv"&gt;$@&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;./logstashd.sh
===================== usage =====================
./logstashd.sh  - enter command line
./logstashd.sh status - show all configured process
./logstashd.sh start  - start program
./logstashd.sh stop  - stop program
./logstashd.sh restart  - restart program
./logstashd.sh reread &amp;amp;&amp;amp; ./logstashd.sh update - update config and just update the modified programs
./logstashd.sh reload - reload config files and restart all programs(stopeed not included)
=================================================

111_indexer                      RUNNING   pid 27058, uptime 1:25:10
indexer                          RUNNING   pid 24731, uptime 1:31:29
supervisor&amp;gt; restart indexer
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里, 我引入了&lt;a href="http://www.stackless.com/binaries/"&gt;stackless python&lt;/a&gt; (独立), 然后装pip/supervisord, 使用supervisord对logstash/es进程进行管理&lt;/p&gt;
&lt;p&gt;使用supervisord管理进程, 有个注意点&lt;/p&gt;
&lt;p&gt;默认supervisord相关的文件在&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;/tmp/supervisor*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而线上, 存在tmp被删/清理了情况, 导致要进行进程启停操作才发现,妈蛋找不到&lt;/p&gt;
&lt;p&gt;处理方式 =&amp;gt; 放到集成安装包的run目录下&lt;/p&gt;
&lt;h4 id="logstashoutput"&gt;注意点: logstash存在两个output时, 必须要保证二者的可用性&lt;/h4&gt;
&lt;p&gt;logstash indexer, 分别转发数据到两个不同的output&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;output {
    elasticsearch {
        hosts =&amp;gt; ["10.1.1.1:8080", "10.1.1.2:8080"]
    }
    redis {
        host =&amp;gt; "10.1.1.3"
        port =&amp;gt; 6379
        password =&amp;gt; "7oEsjqUNoTdgE4"
        data_type =&amp;gt; "list"
        key =&amp;gt; "log_queue"
        db =&amp;gt; 0
        batch =&amp;gt; true
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 若是redis挂了, 则日志也不会刷到es中, 所以, 需要同时保证所有output的可用性&lt;/p&gt;
&lt;p&gt;对于redis, 可以进行进程监控, 发现挂了的话, 告警并同时重启(可以crontab一分钟检查一次)&lt;/p&gt;
&lt;h4 id="elkagent_ip"&gt;优化点: ELK增加agent_ip字段&lt;/h4&gt;
&lt;p&gt;需求: 在实际使用中, 有时候需要反向根据查询结果, 获知日志的来源机器&lt;/p&gt;
&lt;p&gt;处理:&lt;/p&gt;
&lt;p&gt;1.先获取ip&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nt"&gt;GetLanIp&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="n"&gt;associated&lt;/span&gt; &lt;span class="n"&gt;LAN&lt;/span&gt; &lt;span class="n"&gt;ip&lt;/span&gt; &lt;span class="n"&gt;address&lt;/span&gt;
     &lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;GetLanIp&lt;/span&gt;
     &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sbin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ifconfig&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;awk&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;
&lt;span class="s1"&gt;         /eth/{&lt;/span&gt;
&lt;span class="s1"&gt;             getline;&lt;/span&gt;
&lt;span class="s1"&gt;             if (/inet addr:(172|10|192)\./) {&lt;/span&gt;
&lt;span class="s1"&gt;                 gsub(".*addr:|  *Bcast.*","");&lt;/span&gt;
&lt;span class="s1"&gt;                 print $0;&lt;/span&gt;
&lt;span class="s1"&gt;                 exit;&lt;/span&gt;
&lt;span class="s1"&gt;             }&lt;/span&gt;
&lt;span class="s1"&gt;         }'&lt;/span&gt;
     &lt;span class="n"&gt;return&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2.放入环境变量&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;ETH1_IP=10.1.1.1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3.修改logstash配置&lt;/p&gt;
&lt;p&gt;注意, 这里是logstash2.x的语法&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    environment {
        add_metadata_from_env =&amp;gt; ["agent_ip", "ETH1_IP"]
        add_field =&amp;gt; {"agent_ip" =&amp;gt;  "%{[@metadata][agent_ip]}" }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="elkutc"&gt;问题: elk的utc问题&lt;/h4&gt;
&lt;p&gt;elasticsearch内部使用的是utc, 存储为long (milliseconds since the epoch)  e.g. timestamp=1420070400000&lt;/p&gt;
&lt;p&gt;可以看下 &lt;a href="https://github.com/chenryn/logstash-best-practice-cn/blob/master/filter/date.md"&gt;es 时间处理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;logstash 接受了这种设定, 往es传数据的时候, 根据UTC, 每天00:00新建一个index&lt;/p&gt;
&lt;p&gt;kibana也接受这种设定, 在查询和展示时根据用户的时区进行处理&lt;/p&gt;
&lt;p&gt;问题描述&lt;/p&gt;
&lt;p&gt;这导致了, 对于东八区, 2015-11-6日, 8点之前, 只有&lt;code&gt;logstash-2015.11.05&lt;/code&gt;这个index, 到8点的时候, 创建新的index &lt;code&gt;logstash-2015.11.06&lt;/code&gt;, 即, 对于我们这个时区的人来说, 一天的数据存在了两个index里面&lt;/p&gt;
&lt;p&gt;同类问题 &lt;a href="https://github.com/elastic/elasticsearch/issues/7375"&gt;Elasticsearch doesn't care about timezone and creates indexes with UTC&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;修正方案1: 修改logstash的数据时间&lt;/p&gt;
&lt;p&gt;logstash团队对于支持localtime的问题, 不予修复 &lt;a href="https://logstash.jira.com/browse/LOGSTASH-973"&gt;讨论&lt;/a&gt;, 但是可以自行去修改logstash的代码&lt;/p&gt;
&lt;p&gt;当然, 可以修改每个logstash indexer的时间, 但是会带来问题 &lt;a href="https://github.com/chenryn/logstash-best-practice-cn/blob/master/filter/date.md#时区问题的解释"&gt;问题&lt;/a&gt;: 1. logstash都要修改&lt;code&gt;getLocalTime&lt;/code&gt; 2.相对时间搜索 3. kibana等相关插件/组件要修正&lt;/p&gt;
&lt;p&gt;运维/升级和后续使用上会有很多地雷&lt;/p&gt;
&lt;p&gt;修正方案2: 不修正&lt;/p&gt;
&lt;p&gt;接受这种设定, 学习kibana, 类似自行确定要搜索的index
对于&lt;code&gt;00:00-08:00&lt;/code&gt;的, 程序处理使用昨天的&lt;code&gt;indexer&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所以, 更好的方式是, 不修正......原来不变的才是最好的&lt;/p&gt;
&lt;h4 id="rolling-restart"&gt;rolling restart&lt;/h4&gt;
&lt;p&gt;当存在配置变更时, 需要重启es集群, 不可能全部重启的, 这样会导致服务不可用....&lt;/p&gt;
&lt;p&gt;所以, 要一个个重启&lt;/p&gt;
&lt;p&gt;先执行&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XPUT 'http://localhost:9200/_cluster/settings' -d '
{
    "transient" : {
        "cluster.routing.allocation.enable" : "none"
    }
}'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, shutdown, 改配置, start&lt;/p&gt;
&lt;p&gt;then : 一定要记得执行, 否则不会执行recovery.....会一直等着&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XPUT 'http://localhost:9200/_cluster/settings' -d '
{
    "transient" : {
        "cluster.routing.allocation.enable" : "all"
    }
}'
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="logstashgrok"&gt;logstash文本解析配置grok语法&lt;/h4&gt;
&lt;p&gt;一个线上的工具, https://grokdebug.herokuapp.com/&lt;/p&gt;
&lt;p&gt;挺好用的, 但是有时候变更频繁相应有些缓慢&lt;/p&gt;
&lt;p&gt;暂时没有找到命令行工具&lt;/p&gt;
&lt;h4 id="grok"&gt;坑: GROK语法&lt;/h4&gt;
&lt;p&gt;上线后发现, 尼玛, 部分应用日志没有被采集&lt;/p&gt;
&lt;p&gt;定位发现, 原来在&lt;code&gt;grok&lt;/code&gt;的解析中使用了&lt;code&gt;WORD&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;而 &lt;code&gt;WORD&lt;/code&gt;: 不支持连字符和下划线&lt;/p&gt;
&lt;p&gt;跪了, 需要自定义&lt;code&gt;LOGFILENAME [a-z\-A-Z0-9_\.]+&lt;/code&gt;放到pattern中&lt;/p&gt;
&lt;p&gt;然后, 搜索的时候, 尼玛, 也搜不到....语法要做处理, 使用&lt;code&gt;raw&lt;/code&gt;, es建索引的时候自动拆掉了导致搜索不到&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{'term': {'app_name.raw': 'nms-t'}}
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="exclude"&gt;做一些exclude&lt;/h4&gt;
&lt;p&gt;有时候需要做一些exclude, 去除比必要采集和监控的日志(进入采集逻辑纯粹是浪费cpu和内存)&lt;/p&gt;
&lt;p&gt;例如, 目录树, 不要监控celery.log&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;logs
├── a
│&amp;nbsp;&amp;nbsp; ├── a.log
│&amp;nbsp;&amp;nbsp; ├── b.log
│&amp;nbsp;&amp;nbsp; └── celery.log
└── b
    ├── c.log
        └── d.log
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;排除部分文件&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;file {
    path =&amp;gt; ["/data/logs/*/*.log"]
    exclude =&amp;gt; ["celery.log", ]
    sincedb_path =&amp;gt; "/data/LogNew/logstash/sincedb/django.sincedb"
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-exclude"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h4 id="_1"&gt;一些相关用到的命令&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;查看plugin版本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;https://www.elastic.co/guide/en/logstash/current/working-with-plugins.html&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;bin/plugin list --verbose
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;create empty index&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XPUT 'http://localhost:9100/logstash-2015.12.15/'
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;查看健康度&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl 'http://localhost:9100/_cluster/health?pretty=true'
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;查看indices&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

curl &lt;span class="s1"&gt;'http://localhost:9100/_cat/indices?v'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort -k 3
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="30crontab"&gt;删除30天前crontab脚本&lt;/h4&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;now&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;date +%Y%m%d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; $now
&lt;span class="nv"&gt;days_30_before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;date -d &lt;span class="s2"&gt;"&lt;/span&gt;$&lt;span class="s2"&gt;now 31 days ago"&lt;/span&gt; +%Y.%m.%d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$da&lt;/span&gt;ys_30_before
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"http://10.1.1.1:9100/logstash-&lt;/span&gt;&lt;span class="nv"&gt;$da&lt;/span&gt;&lt;span class="s2"&gt;ys_30_before"&lt;/span&gt;
curl -XDELETE &lt;span class="s2"&gt;"http://10.1.1.1:9100/logstash-&lt;/span&gt;&lt;span class="nv"&gt;$da&lt;/span&gt;&lt;span class="s2"&gt;ys_30_before"&lt;/span&gt; &amp;gt; /dev/null 2&amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;1
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="_2"&gt;尚未处理&lt;/h4&gt;
&lt;p&gt;logstash2.1 muline codec, 配置多个数据来源, 存在串的情况, 生产中大数据量有, 小规模没有复现....&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;好了, 先这些, 还有一些窝在某些目录下, 后续整理好了发&lt;/p&gt;
&lt;p&gt;wklken&lt;/p&gt;
&lt;p&gt;2016-02-16&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Tue, 16 Feb 2016 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2016-02-16:posts/2016/02/16/elk-about-upgrade.html</guid><category>system</category></item><item><title>Elasticsearch几个问题的解决</title><link>http://www.wklken.me/posts/2015/05/23/elasticsearch-issues.html</link><description>&lt;p&gt;今天惯例看统计报表, 才发现es集群悲剧了......昨天下午到今天早上, 持续报错, 写了1G的错误日志&amp;gt;_&amp;lt;#(暂无监控....)&lt;/p&gt;
&lt;p&gt;当前状态: 单台机器, 单节点(空集群), 200W 数据, 500+shrads,  约3G大小&lt;/p&gt;
&lt;p&gt;以下是几个问题的处理过程&lt;/p&gt;
&lt;h3 id="unassigned-shards"&gt;大量unassigned shards&lt;/h3&gt;
&lt;p&gt;其实刚搭完运行时就是&lt;code&gt;status: yellow&lt;/code&gt;(所有主分片可用，但存在不可用的从分片), 只有一个节点, 主分片启动并运行正常, 可以成功处理请求, 但是存在&lt;code&gt;unassigned_shards&lt;/code&gt;, 即存在没有被分配到节点的从分片.(只有一个节点.....)&lt;/p&gt;
&lt;p&gt;.当时数据量小, 就暂时没关注. 然后, 随着时间推移,  出现了大量unassigned shards&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XGET http://localhost:9200/_cluster/health\?pretty
{
  "cluster_name" : "elasticsearch",
  "status" : "yellow",
  "timed_out" : false,
  "number_of_nodes" : 2,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 538,
  "active_shards" : 538,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 558,
"number_of_pending_tasks" : 0
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理方式:  找了台内网机器, 部署另一个节点(保证&lt;code&gt;cluster.name&lt;/code&gt;一致即可, 自动发现, 赞一个). 当然, 如果你资源有限只有一台机器,  使用相同命令再启动一个es实例也行. 再次检查集群健康, 发现&lt;code&gt;unassigned_shards&lt;/code&gt;减少, &lt;code&gt;active_shards&lt;/code&gt;增多.&lt;/p&gt;
&lt;p&gt;操作完后, 集群健康从&lt;code&gt;yellow&lt;/code&gt;恢复到 &lt;code&gt;green&lt;/code&gt;&lt;/p&gt;
&lt;h3 id="status-red"&gt;status: red&lt;/h3&gt;
&lt;p&gt;集群健康恶化了......&lt;/p&gt;
&lt;p&gt;这次检查发现是&lt;code&gt;status: red&lt;/code&gt;(存在不可用的主要分片)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XGET http://localhost:9200/_cluster/health\?pretty
{
  "cluster_name" : "elasticsearch",
  "status" : "red",    // missing some primary shards
  "timed_out" : false,
  "number_of_nodes" : 4,
  "number_of_data_nodes" : 2,
  "active_primary_shards" : 538,
  "active_shards" : 1076,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 20,  // where your lost primary shards are.
  "number_of_pending_tasks" : 0
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="fix-unassigned-shards"&gt;fix unassigned shards&lt;/h3&gt;
&lt;p&gt;开始着手修复&lt;/p&gt;
&lt;p&gt;查看所有分片状态&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XGET http://localhost:9200/_cat/shards
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;找出&lt;code&gt;UNASSIGNED&lt;/code&gt;分片&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -s "http://localhost:9200/_cat/shards" | grep UNASSIGNED
pv-2015.05.22                 3 p UNASSIGNED
pv-2015.05.22                 3 r UNASSIGNED
pv-2015.05.22                 1 p UNASSIGNED
pv-2015.05.22                 1 r UNASSIGNED
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查询得到master节点的唯一标识&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl 'localhost:9200/_nodes/process?pretty'

{
  "cluster_name" : "elasticsearch",
  "nodes" : {
    "AfUyuXmGTESHXpwi4OExxx" : {
      "name" : "Master",
     ....
      "attributes" : {
        "master" : "true"
      },
.....
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;执行reroute(分多次, 变更shard的值为&lt;code&gt;UNASSIGNED&lt;/code&gt;查询结果中编号, 上一步查询结果是1和3)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl -XPOST 'localhost:9200/_cluster/reroute' -d '{
        "commands" : [ {
              "allocate" : {
                  "index" : "pv-2015.05.22",
                  "shard" : 1,
                  "node" : "AfUyuXmGTESHXpwi4OExxx",
                  "allow_primary" : true
              }
            }
        ]
    }'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;批量处理的脚本(当数量很多的话, 注意替换node的名字)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; index in &lt;span class="k"&gt;$(&lt;/span&gt;curl  -s &lt;span class="s1"&gt;'http://localhost:9200/_cat/shards'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep UNASSIGNED &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;'{print $1}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort &lt;span class="p"&gt;|&lt;/span&gt; uniq&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; shard in &lt;span class="k"&gt;$(&lt;/span&gt;curl  -s &lt;span class="s1"&gt;'http://localhost:9200/_cat/shards'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep UNASSIGNED &lt;span class="p"&gt;|&lt;/span&gt; grep $index &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;'{print $2}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort &lt;span class="p"&gt;|&lt;/span&gt; uniq&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
        &lt;span class="nb"&gt;echo&lt;/span&gt;  $index $shard

        curl -XPOST &lt;span class="s1"&gt;'localhost:9200/_cluster/reroute'&lt;/span&gt; -d &lt;span class="s2"&gt;"{&lt;/span&gt;
&lt;span class="s2"&gt;            'commands' : [ {&lt;/span&gt;
&lt;span class="s2"&gt;                  'allocate' : {&lt;/span&gt;
&lt;span class="s2"&gt;                      'index' : &lt;/span&gt;$&lt;span class="s2"&gt;index,&lt;/span&gt;
&lt;span class="s2"&gt;                      'shard' : &lt;/span&gt;$&lt;span class="s2"&gt;shard,&lt;/span&gt;
&lt;span class="s2"&gt;                      'node' : 'Master',&lt;/span&gt;
&lt;span class="s2"&gt;                      'allow_primary' : true&lt;/span&gt;
&lt;span class="s2"&gt;                  }&lt;/span&gt;
&lt;span class="s2"&gt;                }&lt;/span&gt;
&lt;span class="s2"&gt;            ]&lt;/span&gt;
&lt;span class="s2"&gt;        }"&lt;/span&gt;

        sleep 5
    &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="too-many-open-files"&gt;&amp;ldquo;Too many open files&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;发现日志中大量出现这个错误&lt;/p&gt;
&lt;p&gt;执行&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl http://localhost:9200/_nodes/process\?pretty
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以看到&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;"max_file_descriptors" : 4096,
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;官方文档中&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure to increase the number of open files descriptors on the machine (or for the user running elasticsearch). Setting it to 32k or even 64k is recommended.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而此时, 可以在系统级做修改, 然后全局生效&lt;/p&gt;
&lt;p&gt;最简单的做法, 在&lt;code&gt;bin/elasticsearch&lt;/code&gt;文件开始的位置加入&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;ulimit -n 64000
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后重启es, 再次查询看到&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;"max_file_descriptors" : 64000,
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;问题解决&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;待续, 目测还有很多坑, 而且随着数据量上来, 会遇到越来越多的坑......&lt;/p&gt;
&lt;p&gt;2015-05-23
于深圳&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sat, 23 May 2015 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2015-05-23:posts/2015/05/23/elasticsearch-issues.html</guid><category>system</category></item><item><title>Logstash+ElasticSearch+Kibana- 实现相对通用的数据收集分析</title><link>http://www.wklken.me/posts/2015/05/08/elk-data-collect.html</link><description>&lt;p&gt;ElasticSearch + Logstash + Kibana, 目前应该算是一套完整的日志收集/存储/统计解决方案. &lt;/p&gt;
&lt;p&gt;在上一篇 &lt;a href="http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html"&gt;Logstash+ElasticSearch+Kibana处理nginx访问日志&lt;/a&gt; 中, 介绍了如何统一处理&lt;code&gt;nginx&lt;/code&gt;日志&lt;/p&gt;
&lt;p&gt;最近正好在做应用日志及上报日志的汇聚和统计工作, 分享下处理方式.&lt;/p&gt;
&lt;p&gt;目标是: 一次搭建, 后面只需要关心输入(日志记录)以及输出(Kibana统计展示)&lt;/p&gt;
&lt;h2 id="_1"&gt;日志&lt;/h2&gt;
&lt;p&gt;日志的来源:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;1. 服务日志: 服务端记录下来的日志, 例如搜索日志等, 内容较为详尽
2. 上报日志: 来自于前端/android/ios/桌面端等, 根据用户操作行为, 上报一些数据, 例如按钮点击量, 转化率等, 也可以上报崩溃日志
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中, 上报日志, 可以制定一套协议, 不同端统一走上报服务接口. 这个服务对性能有要求, 具体协议需要足够灵活, 支持各类统计分析需求. 使用golang写了一个 &lt;a href="https://github.com/wklken/http_json_logger"&gt;http_json_logger&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;日志在不同应用/机器记录后, 可以通过&lt;code&gt;rsync&lt;/code&gt;/&lt;code&gt;nfs&lt;/code&gt;/&lt;code&gt;scp&lt;/code&gt;等, 汇总到一个地方进行统一处理, 也可以通过多个&lt;code&gt;logstash shipper&lt;/code&gt;进行汇聚&lt;/p&gt;
&lt;p&gt;关于日志格式,  统一使用&lt;code&gt;json&lt;/code&gt;格式, 落地过程中包含平台&lt;code&gt;{platform}&lt;/code&gt;, 以及 项目&lt;code&gt;{project}&lt;/code&gt;, 模块&lt;code&gt;{module}&lt;/code&gt;,  落地时间&lt;code&gt;ts&lt;/code&gt;等&lt;/p&gt;
&lt;p&gt;为什么要落地: 落地成文件, 定时压缩备份存档, 不论日志处理系统是否有问题, 都能保证数据已经存下来了.&lt;/p&gt;
&lt;p&gt;当然, 也可以考虑使用logstash监听端口, 分别落地到文件及转入es, 没具体实践过.&lt;/p&gt;
&lt;p&gt;在这一步, 我的处理方案是:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;1. 使用统一上报接口, 日志落地到上报服务的数据盘

2. 服务端服务日志, 同一台机器在相同数据盘, 使用同一个logstash shipper进行汇聚

对日志文件名等, 不强求一致性, 你可以认为, 不同项目/不同模块的json都可以直接记录到同一个日志文件(虽然不鼓励这么做), 通过日志body内容而不是日志文件名来处理 
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="logstash-shipper"&gt;汇聚: logstash shipper&lt;/h2&gt;
&lt;p&gt;不得不说, logstash的确是神器&lt;/p&gt;
&lt;p&gt;上一步, 日志中强制日志中每一行是一条json记录.  同时json body中记录了时间戳(timestamp, &lt;code&gt;ts&lt;/code&gt;字段)&lt;/p&gt;
&lt;p&gt;这一步, 配置 &lt;code&gt;logstash&lt;/code&gt;将某些目录下的所有日志文件进行汇聚&lt;/p&gt;
&lt;p&gt;配置示例:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;input {
  file {
    path =&amp;gt; [ "/data/collect/ios/*.log", "/data/collect/android/*.log", "/data/collect/web/*.log", "/data/collect/wap/*.log" ]
    start_position =&amp;gt; "beginning"
    codec =&amp;gt; json
  }
}

# make ts to @timestamp
filter {
  date {
    match =&amp;gt; [ "ts" , "dd/MMM/YYYY:HH:mm:ss Z", "UNIX" ]
  }
}


output {
    redis { host =&amp;gt; "127.0.0.1" data_type =&amp;gt; "list" key =&amp;gt; "logstash:collect:log" }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这时候, 所有日志集中到了一个地方&lt;/p&gt;
&lt;h2 id="es"&gt;处理并存储到es&lt;/h2&gt;
&lt;p&gt;首先, 从redis中读取消息体, 检查并丢弃一些信息, 然后,  根据消息体内&lt;code&gt;platform&lt;/code&gt;/ &lt;code&gt;project&lt;/code&gt;/&lt;code&gt;module&lt;/code&gt;, 分配到es不同的&lt;code&gt;index&lt;/code&gt;
可以根据需要控制粒度&lt;/p&gt;
&lt;p&gt;配置示例&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;input {
  redis {
    host =&amp;gt; "127.0.0.1"
    port =&amp;gt; "6379"
    key =&amp;gt; "logstash:collect:log"
    data_type =&amp;gt; "list"
    codec  =&amp;gt; "json"
    type =&amp;gt; "logstash-collect-log"
    tags =&amp;gt; ["collect"]
  }
}


# drop invalid record
filter {
    if ![platform] {
        drop {}
    }
    if ![project] {
        drop {}
    }
    if ![module] {
        drop {}
    }
}

output {
    elasticsearch {
      host =&amp;gt; "127.0.0.1"
      index =&amp;gt; "%{platform}-%{project}-%{module}-%{+YYYY.MM.dd}"
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="es_1"&gt;ES&lt;/h2&gt;
&lt;p&gt;你会发现, es已经的index中已经有了具体的数据. json中的每个字段都有......&lt;/p&gt;
&lt;h2 id="_2"&gt;然后呢?&lt;/h2&gt;
&lt;p&gt;整套调通之后, 接下来的工作呢?&lt;/p&gt;
&lt;p&gt;假设来了个统计需求&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分析需求, 拆解, 确定统计维度, 需要上报的字段等, 根据协议, 确定&lt;code&gt;{platform}/{project}/{module}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;前端/客户端等, 根据协议, 调用上报接口, 执行数据上报&lt;/li&gt;
&lt;li&gt;到&lt;code&gt;kibana&lt;/code&gt;,  找到对应&lt;code&gt;index&lt;/code&gt;, 根据需求配置对应的展现&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所有的一般性统计需求, 都可以通过&lt;code&gt;三板斧&lt;/code&gt;直接搞定, 只需处理输入以及输出, 没有任何额外工作.&lt;/p&gt;
&lt;h2 id="_3"&gt;最后&lt;/h2&gt;
&lt;p&gt;目前量不大, 完美解决了快速迭代中各类原先处理起来十分困难的统计需求和日志分析(原来要自己上报汇聚数据, 自己拷贝到同一台机器, 自己写统计脚本, 存库, 还得自己撸前端, 搞完之后还被黑说: &lt;code&gt;花了那么多时间, 只搞出个这么反人类的/丑/不是我想要的.....界面&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;当然, 随着业务发展, 各类日志的量都会逐渐上来, 对性能/存储的要求会越来越高, 但是&lt;code&gt;elk&lt;/code&gt;本身对横向扩容只是非常完美, 在相当长一段时间内, 应该可以&lt;code&gt;hold&lt;/code&gt;住.(老大, 我要加机器/硬盘/内存/CPU)&lt;/p&gt;
&lt;p&gt;ok, 先这些&lt;/p&gt;
&lt;p&gt;wklken&lt;/p&gt;
&lt;p&gt;2015-05-08 于深圳&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Fri, 08 May 2015 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2015-05-08:posts/2015/05/08/elk-data-collect.html</guid><category>system</category></item><item><title>Logstash+ElasticSearch+Kibana处理nginx访问日志</title><link>http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html</link><description>&lt;p&gt;&lt;code&gt;ELK&lt;/code&gt;似乎是当前最为流行的日志收集-存储-分析的全套解决方案.&lt;/p&gt;
&lt;p&gt;去年年初, 公司里已经在用, 当时自己还&lt;code&gt;山寨&lt;/code&gt;了一个统计系统(postgresql-echarts, 日志无结构化, json形式存储到postgresql, 构建统一前端配置生成, 调用统一查询接口, &lt;a href="http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html"&gt;具体细节&lt;/a&gt;), 已经过了一年有余.&lt;/p&gt;
&lt;p&gt;一年刚好, 发生了很多事, 那套系统不知现在如何了.&lt;/p&gt;
&lt;p&gt;在新的公司, 一切都得从0到1, 近期开始关注日志/数据上报/统计, 以及后续的数据挖掘等.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;搭建, 测试并上线了一套简单的系统, 初期将所有服务器的nginx日志, 以及搜索日志进行处理.&lt;/p&gt;
&lt;p&gt;&lt;img alt="elk" src="/imgs/system/elk.png"/&gt;&lt;/p&gt;
&lt;p&gt;下面主要介绍对nginx日志进行处理的过程, 不是针对&lt;code&gt;elk&lt;/code&gt;的介绍, 所有涉及ip的地方都改成&lt;code&gt;127.0.0.1&lt;/code&gt;了, 根据自己环境进行修改&lt;/p&gt;
&lt;h3 id="1-nginx-logstash-shipper-redis"&gt;1. nginx日志 -&amp;gt; logstash shipper -&amp;gt; redis&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;centos&lt;/code&gt;使用&lt;code&gt;yum&lt;/code&gt;安装&lt;code&gt;nginx&lt;/code&gt;后, 默认&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;中的日志格式定义为:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;log_format  main  '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;remote_addr&lt;/span&gt;&lt;span class="x"&gt; - &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;remote_user&lt;/span&gt;&lt;span class="x"&gt; [&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;time_local&lt;/span&gt;&lt;span class="x"&gt;] "&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;request&lt;/span&gt;&lt;span class="x"&gt;" '&lt;/span&gt;
&lt;span class="x"&gt;                  '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;status&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;body_bytes_sent&lt;/span&gt;&lt;span class="x"&gt; "&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;http_referer&lt;/span&gt;&lt;span class="x"&gt;" '&lt;/span&gt;
&lt;span class="x"&gt;                  '"&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;http_user_agent&lt;/span&gt;&lt;span class="x"&gt;" "&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;http_x_forwarded_for&lt;/span&gt;&lt;span class="x"&gt;"';&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后在具体&lt;code&gt;server&lt;/code&gt;配置中使用&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;access_log /data/logs/nginx/{PROJECT_NAME}_access.log main;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 我们需要做的是, 将&lt;code&gt;access log&lt;/code&gt;通过&lt;code&gt;logstash shipper&lt;/code&gt;读取, 转&lt;code&gt;json&lt;/code&gt;, 发送到&lt;code&gt;redis&lt;/code&gt;, 由后续的&lt;code&gt;logstash indexer&lt;/code&gt;进行处理&lt;/p&gt;
&lt;p&gt;步骤&lt;/p&gt;
&lt;p&gt;1.在日志所在机器部署&lt;code&gt;logstash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2.在&lt;code&gt;logstash&lt;/code&gt;安装目录下的&lt;code&gt;patterns&lt;/code&gt;中加入一个文件&lt;code&gt;nginx&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;内容(与上面的&lt;code&gt;log_format&lt;/code&gt;相对应)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;NGUSERNAME [a-zA-Z\.\@\-\+_%]+
NGUSER %{NGUSERNAME}
NGINXACCESS %{IPORHOST:clientip} - %{NOTSPACE:remote_user} \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NOTSPACE:http_x_forwarded_for}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3.增加一个&lt;code&gt;logstash&lt;/code&gt;配置文件: &lt;code&gt;logstash-project-access-log.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意, input的file, filter的grok, output的redis-key&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;input {
file {
    path =&amp;gt; [ "/data/logs/nginx/xxxx_access.log" ]
    start_position =&amp;gt; "beginning"
}
}

filter {
mutate { replace =&amp;gt; { "type" =&amp;gt; "nginx_access" } }
grok {
    match =&amp;gt; { "message" =&amp;gt; "%{NGINXACCESS}" }
}
date {
    match =&amp;gt; [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
}
geoip {
    source =&amp;gt; "clientip"
}
}


output {
redis { host =&amp;gt; "127.0.0.1" data_type =&amp;gt; "list" key =&amp;gt; "logstash:xxxx:access_log" }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4.使用&lt;code&gt;supervisor&lt;/code&gt;启动&lt;code&gt;shipper&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;[program:logstash_xxxx_shipper]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/logstash/bin/logstash -f /var/shell/logstash/configs/nginx-xxxx-shipper.conf&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;log_stdout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;log_stderr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;logfile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/logs/logstash/logstash_xxxx_access.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="2-redis-logstash-indexer-elasticsearch"&gt;2. redis -&amp;gt; logstash indexer -&amp;gt; elasticsearch&lt;/h3&gt;
&lt;p&gt;注意, input的redis为上一步redis配置, key要对应, output的elasticsearch配置, &lt;code&gt;index&lt;/code&gt;指定了最终es中存储对应的index, 加日期, 方便对日志进行定期删除&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;input {
redis {
    host =&amp;gt; "127.0.0.1"
    port =&amp;gt; "6379"
    key =&amp;gt; "logstash:xxxx:access_log"
    data_type =&amp;gt; "list"
    codec  =&amp;gt; "json"
    type =&amp;gt; "logstash-arthas-access"
    tags =&amp;gt; ["arthas"]
}
}

output {
elasticsearch {
    host =&amp;gt; "127.0.0.1"
    index =&amp;gt; "logstash-arthas-access-%{+YYYY.MM.dd}"
}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="3-elasticsearch-kibana"&gt;3. elasticsearch -&amp;gt; kibana&lt;/h3&gt;
&lt;p&gt;剩下的其实没什么了, 启动&lt;code&gt;kibana&lt;/code&gt;后, 配置好指向的&lt;code&gt;es&lt;/code&gt;, 就可以在&lt;code&gt;kibana&lt;/code&gt;中查看到实时的日志数据&lt;/p&gt;
&lt;p&gt;demo环境截图&lt;/p&gt;
&lt;p&gt;&lt;img alt="kibana-nginx" src="/imgs/system/kibana-nginx.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kibana&lt;/code&gt;中, 支持各种统计, 着实让人惊艳了一把.&lt;/p&gt;
&lt;p&gt;除了基本的nginx日志, 还需要在各类url入口, 加入平台, 渠道等信息, 这样通过nginx访问日志, 可以统计到更多的信息&lt;/p&gt;
&lt;p&gt;当然, 如果需要一些更为精确/特殊的统计, 需要自行进行数据上报的工作.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="_2"&gt;后续&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;更多的类型的日志聚合, 包括各类访问日志, 统计上报日志等, 日志落地成文件, 永久留存, 转入es中, 只留存三个月&lt;/li&gt;
&lt;li&gt;如何对各类数据进行拆分/汇总&lt;/li&gt;
&lt;li&gt;ELK整体部署/运维/扩容等, 包括数据清理&lt;/li&gt;
&lt;li&gt;基于ES日志的业务自定义统计后台(kibana无法满足一些具体业务的统计需求)&lt;/li&gt;
&lt;li&gt;为什么不使用&lt;code&gt;logstash forwarder&lt;/code&gt;, 因为目前日志组成等较为简单, 简单处理 , 后续需要用到时再考虑&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h1 id="_4"&gt;其他&lt;/h1&gt;
&lt;h2 id="1-logformatgrok"&gt;1. 关于&lt;code&gt;logformat&lt;/code&gt;和对应&lt;code&gt;grok&lt;/code&gt;的配置&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;grok&lt;/code&gt;是&lt;code&gt;logstash&lt;/code&gt;的一个插件,  &lt;a href="http://logstash.net/docs/1.4.2/filters/grok"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Grok is currently the best way in logstash to parse crappy unstructured log data into something structured and queryable&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以, 我们在处理&lt;code&gt;nginx&lt;/code&gt;日志时, 需要根据具体&lt;code&gt;logformat&lt;/code&gt;定义对应的&lt;code&gt;grok&lt;/code&gt;表达式&lt;/p&gt;
&lt;p&gt;除了上面例子中用的那套,  另一份&lt;/p&gt;
&lt;p&gt;logformat&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;  log_format logstash '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;http_host&lt;/span&gt;&lt;span class="x"&gt; '&lt;/span&gt;
&lt;span class="x"&gt;                      '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;remote_addr&lt;/span&gt;&lt;span class="x"&gt; [&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;time_local&lt;/span&gt;&lt;span class="x"&gt;] '&lt;/span&gt;
&lt;span class="x"&gt;                      '"&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;request&lt;/span&gt;&lt;span class="x"&gt;" &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;status&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;body_bytes_sent&lt;/span&gt;&lt;span class="x"&gt; '&lt;/span&gt;
&lt;span class="x"&gt;                      '"&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;http_referer&lt;/span&gt;&lt;span class="x"&gt;" "&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;http_user_agent&lt;/span&gt;&lt;span class="x"&gt;" '&lt;/span&gt;
&lt;span class="x"&gt;                      '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;request_time&lt;/span&gt;&lt;span class="x"&gt; '&lt;/span&gt;
&lt;span class="x"&gt;                      '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;upstream_response_time&lt;/span&gt;&lt;span class="x"&gt;';&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;patterns/nginx&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;NGUSERNAME [a-zA-Z\.\@\-\+_%]+
NGUSER %{NGUSERNAME}
NGINXACCESS %{IPORHOST:http_host} %{IPORHOST:clientip} \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NUMBER:request_time:float} %{NUMBER:upstream_time:float}
NGINXACCESS %{IPORHOST:http_host} %{IPORHOST:clientip} \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NUMBER:request_time:float}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果想自行定义, 可以使用 &lt;a href="https://grokdebug.herokuapp.com/"&gt;grokdebug&lt;/a&gt;, 将要解析的日志和配置的正则放入, 可以查看最终得到的结构化数据&lt;/p&gt;
&lt;h2 id="2-elasticsearch"&gt;2. elasticsearch插件&lt;/h2&gt;
&lt;p&gt;初期只安装了一个 &lt;a href="https://github.com/lmenezes/elasticsearch-kopf"&gt;kopf&lt;/a&gt;, web界面查看&lt;/p&gt;
&lt;h2 id="3-supervisor"&gt;3. supervisor&lt;/h2&gt;
&lt;p&gt;建议使用&lt;code&gt;supervisor&lt;/code&gt;对&lt;code&gt;elk&lt;/code&gt;进行管理,(ps. 不要用yum自带的, 版本太旧好多坑, 浪费1小时......使用pip install安装最新版本即可)&lt;/p&gt;
&lt;p&gt;配置示例&lt;code&gt;elk.conf&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;[program:elasticsearch]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/elk/elasticsearch/bin/elasticsearch&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;

&lt;span class="k"&gt;[program:kibana]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/elk/kibana/bin/kibana&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;

&lt;span class="k"&gt;[program:logstash_arthas]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/elk/logstash/bin/logstash -f /var/shell/elk/logstash/config/xxxx_access.conf&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;log_stdout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;log_stderr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;logfile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/logs/elk/logstash/logstash_arthas_access.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="4-logstash"&gt;4. logstash坑&lt;/h2&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;start_position =&amp;gt; "beginning"
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;logstash, 会记录一份文件读到的位置, 在$HOME/.sincedb_xxxxx 如果要让logstash重新读取文件, 删除之即可, 重启&lt;code&gt;shipper&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;但是你可能发现es中重复记录了, 这是因为, 在&lt;code&gt;output&lt;/code&gt;中, 没有定义存储到es时使用的&lt;code&gt;document_id&lt;/code&gt;, es全部当成新纪录存入, 导致数据重复&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sun, 26 Apr 2015 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2015-04-26:posts/2015/04/26/elk-for-nginx-log.html</guid><category>system</category></item><item><title>基于 PostgreSQL 的数据统计系统</title><link>http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html</link><description>&lt;p&gt;看到标题就知道我要写什么了, 这是之前一个项目的小结吧, 自己对统计的一些认识和看法.&lt;/p&gt;
&lt;p&gt;当时从前到后, 包括技术选型, 花了接近一个月的时间, 也在生产上用了两三个月, 一致在持续维护, 做完图表配置化已然接近完工, 无奈后来离开了, 不过目前应该还在运转&lt;/p&gt;
&lt;p&gt;至于源代码, 暂时不考虑开源, 太渣(其中在看了几天js情况下, 自己撸了1000行js的前端框架, 质量堪忧), 全套用python实现.&lt;/p&gt;
&lt;p&gt;提供一种快速实现运营统计需求的思路.&lt;/p&gt;
&lt;p&gt;(图为百度 echarts 示例)&lt;/p&gt;
&lt;p&gt;&lt;img alt="statistics" src="/imgs/system/statistics.png"/&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="_1"&gt;一. 场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;统计&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所谓统计, 抽象出来就是计数而已(还有各个计数之间的算术运算). 再具体一些, 根据不同维度进行计数.&lt;/p&gt;
&lt;p&gt;而统计后台, 无外乎数据的输入, 处理, 及输出.&lt;/p&gt;
&lt;p&gt;对于实时性, 一般会以天为单位进行统计.&lt;/p&gt;
&lt;p&gt;而在具体业务场景下, 需要计数的数据来源于各个项目和同一个项目的不同机器(分布式部署), 就需要考虑, 如何将日志进行汇聚, 如何更为便捷地进行处理, 存储, 以及展现.&lt;/p&gt;
&lt;p&gt;其中要考虑, 需求是不断在变化的, 如何将成本降到最低?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以往的统计方式:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;分析统计需求 -&amp;gt; 修改项目记录日志内容和格式(到磁盘) -&amp;gt; 自行将日志汇总到一台机器(rsync) -&amp;gt; crontab脚本分析日志(要删或备份历史数据) -&amp;gt; 新建db表, 存储统计结果 -&amp;gt; 写管理后台, 查询统计结果(最繁琐) -&amp;gt; 处理分页/图表等
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;虽然每次耗时或许并不会太长(0.5-2d, 视需求大小), 但对于不同项目和需求变更, 这些工作都是纯体力毫无技术含量的枯燥工作, 可以说是无意义的资源浪费.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新的方式&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;分析统计需求 -&amp;gt; 确认日志内容和格式  -&amp;gt; 统计后台配置输入/处理/输出逻辑 -&amp;gt; 查看结果
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;说白了就是, 处理统计需求变成了 &lt;code&gt;写sql&lt;/code&gt; + &lt;code&gt;配置&lt;/code&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="_2"&gt;二. 处理思路&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;大体思路如下(从后往前):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;1. 将日志进行汇总
2. 日志格式一致化
3. 将日志导入到一个容器中
4. 便捷地通过容器进行计算(计数)
5. 统计结果进行统一存储
6. 提供统一的查询接口
7. 提供前端框架组件, 可以通过配置调用统一查询接口, 并对数据进行分页及图表化
8. 提供配置入口, 可以配置日志入口, 处理逻辑, 展现逻辑. 即完全地配置化
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;需要统一的地方:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;日志格式
容器存储
报告存储
查询接口
前端组件
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;系统成型后&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;增加/修改统计需求: 只需要在后台配置数据来源(日志), 处理逻辑(一段 sql), 展示逻辑(一段前端 json配置), 就可以实现图标
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;h3 id="_3"&gt;三. 具体&lt;/h3&gt;
&lt;h3 id="0"&gt;0. 基本架构&lt;/h3&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;             ----------------------------------------------
            |      日志(UniteStats or ApplicationLogs)     |
             ----------------------------------------------
                              ||
                 ---------------------------
                |        load处理程序        |
                 ---------------------------
                              ||
                ___________________________
               |存储容器--计算容器           |
               |                          |
               |  Container(Postgresql)   |   //json - sql - 聚集函数
               |                          |
               |___________________________
                             ||
            --------------------------------------
           |        [自定义统计脚本-查询逻辑及报告表]  |
            --------------------------------------
                             ||
            ---------------------------------------
           |            统计报告                    |
            ---------------------------------------
                            ||
            ---------------------------------------
           |            统一查询接口                |
            ---------------------------------------
                            ||
             ------------------------------------
            |      [自定义前端-使用统一库-配置生成]   |
             ------------------------------------
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="1"&gt;1. 日志格式&lt;/h3&gt;
&lt;p&gt;日志, 即文本.&lt;/p&gt;
&lt;p&gt;但是文本存在各种格式, 例如常见的&amp;rsquo;\t&amp;rsquo;分隔的列, csv, json, xml等等.&lt;/p&gt;
&lt;p&gt;这里的要求是: 一定要满足自描述, 易读(人), 易处理(生成和解析).&lt;/p&gt;
&lt;p&gt;最终选择了&lt;code&gt;json&lt;/code&gt;. 将原先无结构数据转成半结构化数据.&lt;/p&gt;
&lt;p&gt;原因之一, &lt;code&gt;容器&lt;/code&gt;对半结构化的数据支持已经非常完善了, 例如postgresql, mongodb等, 对于后续计算很重要.&lt;/p&gt;
&lt;p&gt;原因之二, 作为一个统一的平台, 我只在乎数据是一份日志, 但是不在乎, 日志里存了些什么, 每个字段的意义, 这些只有平台的使用者需要知道. 否则带来很大一个问题是, 对于使用者在新增或变更一份日志格式时, 需要明确告诉系统这份日志各个字段是什么(名称和类型), 复杂化了&lt;/p&gt;
&lt;p&gt;到这里, 我们统一了日志的格式, 记录为json, 每条记录一行.&lt;/p&gt;
&lt;h3 id="2"&gt;2. 日志收集汇总&lt;/h3&gt;
&lt;p&gt;目的: 将日志汇总到同一台机器上, 便于统一处理&lt;/p&gt;
&lt;p&gt;命名规则: &lt;code&gt;$THE_LOG_PATH/{projectName}/{projectName}_{moduleName}_{ip}_{yyMMdd}.log&lt;/code&gt; (示例)&lt;/p&gt;
&lt;p&gt;日志汇总的方案有很多:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;scp
rsync
nfs
logstash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最终的处理方案: 数据量小, 同一个机房, 使用NFS将日志汇总到目录, 不同机房, 使用rsync进行汇总. 如果数据量大, 可以考虑使用logstash, 直接将日志经过节点处理实时写到一台机器上(就不要分别记录到各自磁盘了).&lt;/p&gt;
&lt;p&gt;扩展: 使用多台机器, 只要保证最终导入同一个库即可.(同一个项目, 同一天存在一张表, 不同机器的日志导入之)&lt;/p&gt;
&lt;p&gt;到这里, 我们将所有json格式的日志汇集到了一起&lt;/p&gt;
&lt;h3 id="3"&gt;3. 导入容器处理&lt;/h3&gt;
&lt;p&gt;目前每个项目的日志格式是,&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{projectName}/{projectName}_{moduleName}_{ip}_{yyMMdd}.log
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们会将同一个项目, 可能来自不同机器的日志导入同一张表&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{projectName}/{projectName}_{moduleName}_*_{yyMMdd}.log
=&amp;gt;
table: projectName_moduleName_yyMMdd
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理方式: 批量入库, 并且清理保留日期外的表&lt;/p&gt;
&lt;p&gt;建议使用批量导入的方式, 速度杠杠的. Postgresql请使用copy命令&lt;/p&gt;
&lt;h3 id="4"&gt;4. 容器&lt;/h3&gt;
&lt;p&gt;一个计算容器, 仅此而已&lt;/p&gt;
&lt;p&gt;技术选型时, 考虑过Mysql/Mongdb/Redis/MariaDB/OrientDB/CouchDB/RethinkDB等等, 最终敲定使用postgresql, 无它, 对json的完美支持, 满足业务: 一定的数据量, 足够简单的统计方式, 足够稳定, 简单易运维等&lt;/p&gt;
&lt;p&gt;提下&lt;code&gt;redis&lt;/code&gt;, 当时做了整套的&lt;code&gt;redis&lt;/code&gt;方案(接口文档都明确完了就差写代码了), 但是后来毙掉了. (典型的拿着锤子满世界都是钉子的案例). 思想是: 流式日志处理, 根据业务需求使用redis counter, 主从, 后台从redis直接取counter进行展示. 脑洞很大, 可以搞定实时/非实时情况, 还可以顺带把各类业务中的counter需求给做了, 以及更为灵活的展现方式, 但是学习成本较高, 对每个写统计的人要求较高(素质, 具备正确的统计思维, 否则会悲剧掉). 再加上业务本身要求实时性并不高, 所以废弃.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MySql&lt;/code&gt; 对 &lt;code&gt;json&lt;/code&gt; 的支持, 相对于 postgresql 而言逊色太多了, 对&lt;code&gt;json&lt;/code&gt;格式存在限制(多层复杂嵌套的情况)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Mongodb&lt;/code&gt; 虽然对&lt;code&gt;json&lt;/code&gt;支持不错, 但是对于数据量较大的情况支持并不好, 并且查询以及运维都会带来一定困难, 对于使用者有一定学习成本&lt;/p&gt;
&lt;p&gt;PostGresql作为容器的好处:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;1. 支持的数据量
2. 查询简单，支持json, 所有sql查询，group by/order by/嵌套子查询，聚集等
3. 各种聚集、统计函数均可用，搞定基本统计查询无障碍（再复杂的都可以）
4. 运维简单
5. 对于开发而言几乎没有学习成本, 会sql再学习下postgresql的json查询
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;示例:
假设搜索日志:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{&amp;lsquo;ip&amp;rsquo;: &amp;lsquo;127.0.0.1&amp;rsquo;,
 &amp;lsquo;keyword&amp;rsquo;: &amp;lsquo;test&amp;rsquo;,
 &amp;lsquo;result_count&amp;rsquo;: &amp;lsquo;1&amp;rsquo;,
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;统计 pv&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;select count(data-&amp;gt;'ip') from search_20141101;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;统计 uv&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;select count(DISTINCT data-&amp;gt;&amp;gt;'ip') from search_20141101;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;无结果数&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;select count(*) from search_20141101 where data-&amp;gt;&amp;gt;'result_count' = '0';
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;搜索热词排行榜&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;select data-&amp;gt;&amp;gt;&amp;rsquo;keyword&amp;rsquo;, count(*)
from search_20141101
where data-&amp;gt;&amp;gt;'result_count' != '0'
group by data-&amp;gt;&amp;gt;&amp;rsquo;keyword&amp;rsquo;
order by count(*) desc
limit 100;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="5"&gt;5. 批处理&lt;/h3&gt;
&lt;p&gt;这里要做的事情, 需要有一个管理后台, 让开发可以配置上传自己的处理脚本, 设定脚本执行时间, 执行参数(处理日期/报告表名), 甚至是执行依赖.&lt;/p&gt;
&lt;p&gt;这里需要形成一个约定&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="err"&gt;报告表名&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;projectName_statsModuleName&lt;/span&gt;
&lt;span class="err"&gt;报告表一些字段名&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;因为统一查询接口需要用到&lt;/span&gt;&lt;span class="o"&gt;):&lt;/span&gt; &lt;span class="err"&gt;日期&lt;/span&gt; &lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
&lt;span class="err"&gt;其他约定字段&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;每天, 系统会扫描并调度任务, 执行, 处理得到统计结果, 存入报告表.&lt;/p&gt;
&lt;p&gt;到这里, 我们每天的统计结果都存入到了报告表中&lt;/p&gt;
&lt;h3 id="6"&gt;6. 输出&lt;/h3&gt;
&lt;p&gt;报告表, 是以时间为维度的, 每条记录带有日期, 每条记录细化到要统计到的精确维度.(具体表现是一个维度会多一列字段), 原则是, 需求分析时充分考虑当前及后续可能的统计需求(要预见还是蛮容易的), 直接将统计维度最细化.&lt;/p&gt;
&lt;p&gt;当然, 如果无法最细化, 后面存在变更, 可以修改统计脚本, 根据情况对历史数据进行重新统计.&lt;/p&gt;
&lt;h3 id="7"&gt;7. 统一查询层&lt;/h3&gt;
&lt;p&gt;一层通用的接口, 支持传入表名, 条件, 需要结果字段, 格式等, 可以对系统中各类报告表进行各种形式的查询, 获取统计结果.&lt;/p&gt;
&lt;h3 id="8"&gt;8. 前端框架及展现&lt;/h3&gt;
&lt;p&gt;是一整套的js款干啊&lt;/p&gt;
&lt;p&gt;分成几块&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成查询表单: 模块化组件, 通过json配置, 自动生成统计查询的表单, 支持各类维度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;配置示例:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;// 产生条件html
    var condition_configs = {
        title: "频道访问统计摘要",
        conditions: [
                {
                    type: "date_begin_to_end", //开始结束日期选择框
                },
                {
                    type: "select",   //下拉框
                    label: "频道",
                    id: "channel",
                    options: [
                        {
                            text: "所有",
                            value: "",
                        },
                        {
                            text: "快速访问",
                            value: "quickaccess",
                        },

                    ]
                },
                {
                    type: "version", //文档框
                },
        ]
    };
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;就会自动生成表单&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;begin_date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;end_date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;组合查询条件: 表单提交时, 根据json配置, 将表单内容/字段/值/表等, 拼接成统一查询层接口需要的请求串&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;查询后数据处理: 将查询后的结果, 根据json配置, 进行转化和展现, 并图表化.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个配置示例:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;一般文本&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    'column': 'date',&lt;/span&gt;
&lt;span class="x"&gt;    'name': '日期',&lt;/span&gt;
&lt;span class="x"&gt;    'type': 'text',&lt;/span&gt;
&lt;span class="x"&gt;},&lt;/span&gt;

&lt;span class="x"&gt;百分比 &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;后面跟的是sql查询结果列名&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    'column': 'uninstall_ratio',&lt;/span&gt;
&lt;span class="x"&gt;    'name': '卸载率',&lt;/span&gt;
&lt;span class="x"&gt;    'type': 'ratio',&lt;/span&gt;
&lt;span class="x"&gt;    'value': '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;uninstall_pv&lt;/span&gt;&lt;span class="x"&gt;/&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;install_pv&lt;/span&gt;&lt;span class="x"&gt;'&lt;/span&gt;
&lt;span class="x"&gt;},&lt;/span&gt;

&lt;span class="x"&gt;公式计算&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    'column': 'the_qvod_link_pv',&lt;/span&gt;
&lt;span class="x"&gt;    'name': '导入链接数',&lt;/span&gt;
&lt;span class="x"&gt;    'type': 'calculate',&lt;/span&gt;
&lt;span class="x"&gt;    'value': '&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;qvod_link_pv&lt;/span&gt;&lt;span class="x"&gt; + &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;qvod_start_pv&lt;/span&gt;&lt;span class="x"&gt;'&lt;/span&gt;
&lt;span class="x"&gt;},&lt;/span&gt;

&lt;span class="x"&gt;列值翻译&lt;/span&gt;
&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    'column': 'channel',&lt;/span&gt;
&lt;span class="x"&gt;    'name': '渠道',&lt;/span&gt;
&lt;span class="x"&gt;    'type': 'text',&lt;/span&gt;
&lt;span class="x"&gt;    'translation': &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;        "all": "all",&lt;/span&gt;
&lt;span class="x"&gt;        "player": "播放器",&lt;/span&gt;
&lt;span class="x"&gt;        "zx": "资讯",&lt;/span&gt;
&lt;span class="x"&gt;        "other": "其他导入",&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;},&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="9"&gt;9. 图表&lt;/h3&gt;
&lt;p&gt;使用百度 &lt;a href="http://echarts.baidu.com/"&gt;echats&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以根据配置, 将统一查询层的接口返回数据直接灌入echats, 生成表单&lt;/p&gt;
&lt;h3 id="10"&gt;10. 过程日志及监控&lt;/h3&gt;
&lt;p&gt;需要一组管理表, 进行任务配置/调度/执行/执行结果, 整个过程中的操作可以配置和查看, 用于监控.&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="_4"&gt;四. 小结&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s Simple, but it works.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;数据情况, 当时大概每天 10G 日志 load 到库(处理前&amp;gt;10G), 每天日志数据大概是五千万条, 具体业务上了大概40个的样子, 每天30分钟左右处理完. 对于开发的改进是, 将原先0.5-2d的工作, 缩减到了1-2小时, 对生产力的提升较为显著.(对于日志数多且单一日志量较小的情况处理尤为便捷)&lt;/p&gt;
&lt;p&gt;适用范围: 对于一般团队应该足够了(流量百万级别), 每个项目每天3-5百万访问量, 日志数据10-20G, 当然, 一直没机会测试上限, 不过只要PostGresql能抗住, 量再大些应该也ok.(可以考虑上elasticsearch)&lt;/p&gt;
&lt;p&gt;以上思路, 仅供借鉴:) 就这样吧&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sun, 16 Nov 2014 20:58:00 +0800</pubDate><guid>tag:www.wklken.me,2014-11-16:posts/2014/11/16/unit-statistics-system.html</guid><category>system</category></item><item><title>简单搜索系统组成总结</title><link>http://www.wklken.me/posts/2014/06/09/search-system.html</link><description>&lt;p&gt;最近在进行离职前交接工作了, 对之前做的一些东西也大概进行了下简单总结.&lt;/p&gt;
&lt;p&gt;今天整理了下, 搜索系统组成简要描述, 一些思想, 不涉及太多具体实现.&lt;/p&gt;
&lt;p&gt;这套系统从开始设计到最终完成, 前前后后花了3个月的样子(计算所有时间投入), 也算是做得感觉比较完善的一套系统.&lt;/p&gt;
&lt;p&gt;上线接近一年, 支持快玩游戏搜索业务(快玩盒子/快玩网站/移动端等), 系统每天百万级的搜索(峰值在250w左右, 应用层两台机器负载均衡, 单机核心层, 单机引擎), 很遗憾, 由于业务所限, 一直没有看到这套系统能支持的量上限, 即使在峰值, 核心层qps大概也才50左右, 预计搜索量到千万级应该没什么压力, 当然, 优化的余地还很多.&lt;/p&gt;
&lt;p&gt;外面正在狂风骤雨, 开始吧&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="_1"&gt;目标&lt;/h3&gt;
&lt;p&gt;当系统数据达到一定量时, 搜索就成为了除类目以外的第二大入口.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;更好的搜索结果(指标: 召回率, 转化率, 排序效果)&lt;/li&gt;
&lt;li&gt;更好的用户体验(下拉提示点击率,相关搜索准确率等)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="_2"&gt;搜索流程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;用户在输入框输入关键词, 此时输入框会下拉提示一些词, 用户可以选择进行搜索&lt;/li&gt;
&lt;li&gt;用户点击, 进行搜索, 前端调用搜索接口&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用层&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;3.1 请求关键词改写, 获得改写后词
3.2 查询缓存是否存在, 存在直接返回缓存内容. 此时, 会记录搜索日志
3.3 不存在缓存, 调用解析输入, 调用核心层接口
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;核心层, 调用引擎接口, 获取搜索结果, 并整合信息, 返回应用层&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;应用层, 获取结果, 此时根据需要, 可能调用相关搜索和热门词服务, 获取必要信息, 最终进行页面渲染, 记录日志, 返回给客户端&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="_3"&gt;系统结构图&lt;/h3&gt;
&lt;p&gt;实现: java(solr)只需配置 + python(所有服务) + golang(suggestion)&lt;/p&gt;
&lt;p&gt;&lt;img alt="search system" src="/imgs/system/search.png"/&gt;&lt;/p&gt;
&lt;h3 id="_4"&gt;系统组成(简单描述)&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;对外服务  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;搜索整体系统,对外提供服务包括&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基本搜索服务
用户输入query, 系统返回筛选并且排序后的结果, 在前端进行展现&lt;/li&gt;
&lt;li&gt;下拉提示服务
用户在输入框输入query时, 下拉框根据输入提示搜索关键词, google/baidu的搜索框&lt;/li&gt;
&lt;li&gt;相关搜索服务
在搜索结果页,根据用户所在的系统(客户端/移动端/网站等)以及关键词,提示搜索query相关的搜索&lt;/li&gt;
&lt;li&gt;热门搜索
在某些业务中,或者前端,展示热门搜索关键词&lt;/li&gt;
&lt;li&gt;关键词改写
对用户输入关键词进行改写, 以获取更好的搜索结果, 或者进行关键词纠错, 转换&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;缓存&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;缓存在整个搜索系统中起到很关键的作用, 各个服务都需要使用缓存进行优化&lt;/p&gt;
&lt;p&gt;系统使用memcached/redis分别进行处理. 整个搜索中用得最多的是下拉提示suggestion, 用户输入关键词整个过程中存在变动都会发起一次请求.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;业务(应用层+核心层)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;核心层, 提供单一职责, 灵活且性能足够的接口&lt;/p&gt;
&lt;p&gt;应用层, 根据不同系统的业务需求进行编写, 调用核心层接口获取数据, 整合搜索结果, 并进行展示渲染&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;元信息(数据元信息+排行信息等)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;业务本身的核心数据, 包含元信息, 元信息中只有少部分需要导入引擎, 建立索引 or 存储, 元信息中还可能包含排序相关的信息, 例如评分等&lt;/p&gt;
&lt;p&gt;排行信息, 主要来自后端统计系统&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;引擎&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对元信息, 进行分析并处理, 建立索引, 存储内容&lt;/p&gt;
&lt;p&gt;并提供搜索, 可以决定排序规则&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;日志系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;负责记录各个服务的日志, 用于统计以及其他服务的数据挖掘&lt;/p&gt;
&lt;p&gt;可以记录每次搜索的时间,用户,关键词,改写词,是否有结果,结果信息, 翻页信息等等&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;算法模块&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对记录日志进行分析, 使用算法生成其他服务需要的数据&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;报告系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对日志进行统计, 计算搜索pv/uv, 无结果率, 搜索关键词排行, 下拉提示点击率等等&lt;/p&gt;
&lt;p&gt;用于关键性指标的统计, 方便针对性优化&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;接下去, 分块简要说明下&lt;/p&gt;
&lt;h3 id="-"&gt;搜索服务-数据层&lt;/h3&gt;
&lt;p&gt;数据存储跟各自业务有关系, 信息录入渠道主要是运营录入或者抓取导入等, 存储使用&lt;code&gt;mysql/postgresql&lt;/code&gt;等数据库&lt;/p&gt;
&lt;p&gt;rank data 主要是由日志系统统计出一些根据涉及排序相关的数据, 例如用户点击次数, 玩次, 评分等等, 会直接影响到结果排序&lt;/p&gt;
&lt;p&gt;注意, 由于这些数据都会存在变更, 所以, 需要存储update_time, 用于引擎增量建立索引.&lt;/p&gt;
&lt;h3 id="-_1"&gt;搜索服务-引擎&lt;/h3&gt;
&lt;p&gt;实现上, 使用的是开源的 &lt;a href="http://lucene.apache.org/solr/"&gt;apache solr&lt;/a&gt;, 版本4.5, 刚才看了下最新版到了4.8了. &lt;/p&gt;
&lt;p&gt;曾经一度想自己去实现, 结果发现复杂化了, 系统设计中, 切忌把实现问题的手段当做问题本身去处理.&lt;/p&gt;
&lt;p&gt;还有很多同类引擎, 可以去对比下.&lt;/p&gt;
&lt;p&gt;选中solr的原因: 简单&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输入, 足够简单的数据提供方式, 通过配置文件定义数据库及sql等信息, 就可以建立元数据到引擎数据的关系, 且有接口可以方便地进行全量/增量更新&lt;/li&gt;
&lt;li&gt;配置简单, 可以配置索引处理方式, 例如中文分词,拼音搜索等, 可以配置不同接口的排序, 可以配置缓存等. ps: 拼音搜索可以使用&lt;code&gt;EdgeNGram&lt;/code&gt;索引处理实现.&lt;/li&gt;
&lt;li&gt;输出, 足够强大的查询接口&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于引擎, 很重要一块是搜索结果排序, &lt;code&gt;solr&lt;/code&gt; 可以很方便地支持自定义排序, 可以依赖于输入数据中的排序字段, 进行公式计算, 得到最终的加权和, 用于决定排序. 这里的公式需要针对业务中影响排序的因素进行分析, 然后不断调整因素的权重, 得到最终的排序效果.&lt;/p&gt;
&lt;p&gt;如果要进行一些其他处理, 可以在应用层或核心层进行额外处理.&lt;/p&gt;
&lt;h3 id="_5"&gt;下拉提示服务&lt;/h3&gt;
&lt;p&gt;前后做了两个版本, 一个版本基于&lt;code&gt;分词-统计-cache&lt;/code&gt;实现的, 后面一个版本基于 &lt;code&gt;trie树-cache&lt;/code&gt;实现.&lt;/p&gt;
&lt;p&gt;元信息直接导出, 以游戏为例, 游戏名+图标+类型+玩次等信息&lt;/p&gt;
&lt;p&gt;主要是针对游戏名进行处理:(原词+拼音+拼音首字母)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;植物大战僵尸 -&amp;gt; [植物大战僵尸, zhiwudazhanjiangshi, zwdzjs]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, 在内存中建立前缀树. 这里使用的是&lt;code&gt;double-arry-trie&lt;/code&gt;实现&lt;/p&gt;
&lt;p&gt;&lt;code&gt;double-array-trie&lt;/code&gt;文章: &lt;a href="http://en.wikipedia.org/wiki/Trie"&gt;What is Trie&lt;/a&gt; | &lt;a href="http://linux.thai.net/~thep/datrie/datrie.html"&gt;An Implementation of Double-Array Trie&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;用户输入query, 没发生一次变化, 发送请求到下拉提示服务, 首先会去命中缓存, 未命中, 进入trie树搜索前缀, 获取此前缀所有后缀, 即获取提示关键词集合, 排序获取权重最高的进行返回(是这个流程, 但实际上没那么简单, 要考虑性能).&lt;/p&gt;
&lt;p&gt;如果不开缓存，实时计算的话，对cpu占用率非常高，每次都要搜索&lt;code&gt;trie&lt;/code&gt;树，所以开启了memcached外部缓存.&lt;/p&gt;
&lt;p&gt;开源了一份, 但并不是线上的实现, 而是优化版本, 但是一直没有机会上到线上看下效果, 有兴趣可以看下 &lt;a href="https://github.com/wklken/suggestion"&gt;suggestion&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="_6"&gt;相关搜索服务&lt;/h3&gt;
&lt;p&gt;目前做得比较简单, 使用同一个用户的搜索关键词链进行分析, 处理成
&lt;code&gt;[ 搜索关键词-后继搜索关键词]&lt;/code&gt;, 并进行统计, 最终获取统计结果.&lt;/p&gt;
&lt;p&gt;这个服务一直没有进行优化, 导致相关搜索的结果并不好, 存在很多bad case(推荐重复的内容/单字符推荐等).&lt;/p&gt;
&lt;p&gt;可以基于算法进行重构.&lt;/p&gt;
&lt;h3 id="_7"&gt;关键词改写&lt;/h3&gt;
&lt;p&gt;关键词改写, 主要分成两类, 一类是输入关键字错误导致无结果(错别字/缺字/多字等), 另一类是输入关键字是业务上某些名称的别名, 系统内没有, 需要转换.&lt;/p&gt;
&lt;p&gt;通过改写, 可以实现纠错以及转换的目的, 使用户能正确获取结果&lt;/p&gt;
&lt;p&gt;关于纠错, 目前处理方式, 用户搜索关键词链, 处理成 &lt;code&gt;[无结果词 - 有结果词]&lt;/code&gt;, 另外还有用户下拉提示点击 &lt;code&gt;[无结果输入词 - 有结果点击词]&lt;/code&gt;, 然后进行统计, 根据一系列规则进行筛选, 获取改写列表.(目前是基于规则的, 优化空间还很大)&lt;/p&gt;
&lt;p&gt;关于业务上的改写, 需要提供入口, 提供给运营人员针对一些术语进行改写, 例如&lt;code&gt;[gta -&amp;gt; 侠盗猎车手]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个服务比较简单粗暴, 计算完成后直接将键值对刷入缓存, 对外提供服务.&lt;/p&gt;
&lt;p&gt;关键词改写需要进行持续的优化, 定期获取新的日志进行批量处理, 加入列表. 优化余地很大, 可以有效降低无结果率.&lt;/p&gt;
&lt;h3 id="_8"&gt;统计&lt;/h3&gt;
&lt;p&gt;主要对每日的搜索日志进行统计, 得到两部分信息:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;报表数据: 不同平台不同渠道的每日pv/uv, 无结果率, 下拉提示点击率等&lt;/li&gt;
&lt;li&gt;排行数据: 不同纬度下搜索排行, 用于反向作用于搜索引擎排序&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h3 id="_9"&gt;一些坑&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;系统使用的&lt;code&gt;memcached&lt;/code&gt;集群作为缓存, 遇到一些坑, 例如&lt;code&gt;key&lt;/code&gt;最大长度250,   &lt;code&gt;key&lt;/code&gt;不能包含空格和控制字符, 存储数据最大1M. 即, 默认对用户的输入不信任(看日志才知道有多少奇葩的搜索query). 切成redis或许会好一些.&lt;/li&gt;
&lt;li&gt;关于备份. 由于业务初期流量一直不大, 所以除了应用层使用&lt;code&gt;nginx&lt;/code&gt;做负载均衡外, 核心层和&lt;code&gt;solr&lt;/code&gt;都使用单机实例. 带来的问题是, 虽然整体负载不高, 但是没有备份, 出现过一次&lt;code&gt;solr&lt;/code&gt;引擎挂到导致搜索整体失效30分钟的故障, 后面对每个单机服务都进行了服务备份, 失效启用.&lt;/li&gt;
&lt;li&gt;需要对整体系统进行监控, 使用&lt;code&gt;sentry&lt;/code&gt;和&lt;code&gt;statsd&lt;/code&gt;, 可以实时监测到流量变化以及程序错误.&lt;/li&gt;
&lt;li&gt;日志很重要, 要针对自己需要了解的指标以及需要统计分析的字段, 设计尽可能完整的日志记录.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h3 id="_10"&gt;一些感想&lt;/h3&gt;
&lt;p&gt;需要确认整体目标, 然后建立关键性指标, 实现基础方案, 上线, 并持续地关注数据, 分析日志以及bad case, 然后进行优化, 观察指标变化. 记得系统最初的召回率84%, 后来一步步提升到了92%. 这是一个长期的, 不断优化的过程.&lt;/p&gt;
&lt;p&gt;很多东西, 都需要自己一步步去摸索和尝试.&lt;/p&gt;
&lt;p&gt;当然, 这只是一个小型的搜索系统, 其中每一个模块都可以针对性地扩展和优化, 使用更好的算法, 达到更好的效果.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It's simple, but it works, that's enough:)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;系统总是跟随业务逐渐成长变化的, 很可惜, 业务夭折, 这个系统可能失去了在这里继续进化的可能. &lt;/p&gt;
&lt;p&gt;希望提供一些可供大家借鉴的方法. That's all.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;先这样吧&lt;/p&gt;
&lt;p&gt;wklken&lt;/p&gt;
&lt;p&gt;2014-06-09 于深圳&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Mon, 09 Jun 2014 00:00:00 +0800</pubDate><guid>tag:www.wklken.me,2014-06-09:posts/2014/06/09/search-system.html</guid><category>system</category></item></channel></rss>